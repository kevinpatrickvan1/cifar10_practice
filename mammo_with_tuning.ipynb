{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2708ee8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import optuna\n",
    "import pickle\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb52c4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to build my own pytorch dataset by pulling together all images from the 5 folders in train/test/val with their\n",
    "# corresponding labels (0...4)\n",
    "train_path = '/sc/arion/projects/shenl03_ml/2022_kevin_mammo/CBIS-DDSM_patch_set/train'\n",
    "val_path = '/sc/arion/projects/shenl03_ml/2022_kevin_mammo/CBIS-DDSM_patch_set/val'\n",
    "test_path = '/sc/arion/projects/shenl03_ml/2022_kevin_mammo/CBIS-DDSM_patch_set/test'\n",
    "\n",
    "\n",
    "#train_img_paths = []\n",
    "#classes = [] # should get a list of 5\n",
    "\n",
    "def get_png_paths(path):\n",
    "    img_paths = []\n",
    "    classes = []\n",
    "    \n",
    "    for p, _, files in os.walk(path):\n",
    "        for f in files:\n",
    "            if '.png' in f:\n",
    "                img_paths.append(os.path.join(p,f))\n",
    "    return img_paths\n",
    "\n",
    "train_img_paths = get_png_paths(train_path)\n",
    "val_img_paths = get_png_paths(val_path)\n",
    "test_img_paths = get_png_paths(test_path)\n",
    "\n",
    "mammo_classes = {'background':0,\n",
    "           'calc_ben':1,\n",
    "           'calc_mal':2,\n",
    "           'mass_ben':3,\n",
    "           'mass_mal':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081e682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom PyTorch Dataset with tuples of image array values and corresponding class represented as integer from mammo_classes dict\n",
    "class MammoDataset(Dataset):\n",
    "    def __init__(self,img_paths,transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        img_path = self.img_paths[i]\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        label = img_path.split('/')[-2] # retrieve label from folder above\n",
    "        label = mammo_classes.get(label) #turn string label into integer\n",
    "        if self.transform:\n",
    "            # apply transformations\n",
    "            # ToTensor() auto converts uint8 to range (0,1)\n",
    "            img = self.transform(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b87900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Normalize() to initial transforms\n",
    "# ToTensor() converts uint8 values to range (0,1)\n",
    "train_tf = transforms.Compose([\n",
    "        transforms.ToTensor(), \n",
    "        transforms.RandomHorizontalFlip(.2), \n",
    "        transforms.RandomVerticalFlip(.1), \n",
    "        transforms.RandomRotation(30), \n",
    "        transforms.Normalize((0.3788, 0.3788, 0.3788),(0.1508, 0.1508, 0.1508))\n",
    "    ])\n",
    "\n",
    "val_tf = transforms.Compose([\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize((0.3788, 0.3788, 0.3788),(0.1508, 0.1508, 0.1508))\n",
    "    ])\n",
    "\n",
    "train_dataset = MammoDataset(train_img_paths,train_tf)\n",
    "val_dataset = MammoDataset(val_img_paths,val_tf)\n",
    "test_dataset = MammoDataset(test_img_paths,val_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923cbb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network that will be used\n",
    "\n",
    "class mammonet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #list of layers used\n",
    "        self.conv1 = nn.Conv2d(3,64,3,1,1)\n",
    "        self.conv2 = nn.Conv2d(64,64,3,1,1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64,128,3,1,1)\n",
    "        self.conv4 = nn.Conv2d(128,128,3,1,1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(128,256,3,1,1)\n",
    "        self.conv6 = nn.Conv2d(256,256,3,1,1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv7 = nn.Conv2d(256,512,3,1,1)\n",
    "        self.conv8 = nn.Conv2d(512,512,3,1,1)\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(512*7*7,5)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #list of order of nn\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.bn1(self.conv2(x))))\n",
    "\n",
    "        x = F.relu(self.bn2(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv4(x))))\n",
    "\n",
    "        x = F.relu(self.bn3(self.conv5(x)))\n",
    "        x = F.relu(self.bn3(self.conv6(x)))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv6(x))))\n",
    "\n",
    "        x = F.relu(self.bn4(self.conv7(x)))\n",
    "        x = F.relu(self.bn4(self.conv8(x)))\n",
    "        x = self.pool(F.relu(self.bn4(self.conv8(x))))\n",
    "\n",
    "        x = F.relu(self.bn4(self.conv8(x)))\n",
    "        x = F.relu(self.bn4(self.conv8(x)))\n",
    "        x = self.pool(F.relu(self.bn4(self.conv8(x))))\n",
    "\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee8a7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    model = mammonet()\n",
    "    model.to(device)\n",
    "    \n",
    "    lr = trial.suggest_float(\"lr\",1e-5,1e-1,log=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    batch_size=trial.suggest_int(\"batch_size\", 2, 6, step=1)\n",
    "    \n",
    "\n",
    "\n",
    "    # Make Dataloaders for each dataset\n",
    "    train_loader = DataLoader(train_dataset,batch_size=2**batch_size,shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset,batch_size=2**batch_size,shuffle=True)\n",
    "\n",
    "    epochs = 20\n",
    "    for epoch in range(epochs):\n",
    "    \n",
    "        total_loss = 0\n",
    "        best_val_acc = -np.inf\n",
    "        model.train()\n",
    "\n",
    "        for i, data in enumerate(train_loader):\n",
    "\n",
    "            # Retrieve inputs\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            #clear gradient\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #forward step\n",
    "            output = model(images)\n",
    "            loss = criterion(output,labels)\n",
    "\n",
    "            #backward step\n",
    "            loss.backward()\n",
    "\n",
    "            #optimize\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "\n",
    "        # Validation loss\n",
    "        val_loss = 0.0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        model.eval()\n",
    "        for i, data in enumerate(val_loader):\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "        accuracy = correct/total\n",
    "        if accuracy > best_val_acc:\n",
    "            best_val_acc = accuracy\n",
    "            # If this model's val acc is best, save/overwrite best model for this trial\n",
    "            trial.set_user_attr('Epoch',epoch)\n",
    "            with open(\"./mammo_models/mammo_trial_{}.pickle\".format(trial.number), \"wb\") as fout:\n",
    "                pickle.dump(model, fout)\n",
    "                \n",
    "        trial.report(accuracy,epoch)\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "            \n",
    "    print(\"Finished Training\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e72936",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "trial = study.best_trial\n",
    "\n",
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))\n",
    "print('Best epoch: {}'.format(trial.user_attrs))\n",
    "# Load the best model.\n",
    "with open(\"./mammo_models/mammo_trial_{}.pickle\".format(trial.number), \"rb\") as fin:\n",
    "    best_model = pickle.load(fin)\n",
    "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete','duration','number'], axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10be47fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test network\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "test_loader = DataLoader(test_dataset,batch_size=2**trial.params[\"batch_size\"],shuffle=False)\n",
    "# no gradients necessary when testing\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        output = best_model(images)\n",
    "        \n",
    "        _, predicted = torch.max(output.data,1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on test images: {100 * correct // total} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
